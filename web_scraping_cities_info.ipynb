{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2ad2c3fd-a67e-4014-b885-30d03b2df9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in this file there are functions to scrap the wikipedia webpages for cities \n",
    "# and push the info to sql database \n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlalchemy\n",
    "from datetime import datetime\n",
    "import re\n",
    "from keys import MySQL_Pass\n",
    "\n",
    "def create_sql_connection():\n",
    "    schema = \"sql_escooter_forecast\"\n",
    "    host = \"127.0.0.1\"\n",
    "    user = \"root\"\n",
    "    password = MySQL_Pass\n",
    "    port = 3306\n",
    "    connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "\n",
    "    return connection_string\n",
    "\n",
    "def get_city_info(urls):\n",
    "    city_population_df = pd.DataFrame(columns=['city', 'population', 'date', 'lat' ,'long', 'country'])\n",
    "    city_df = pd.DataFrame(columns=['city_id', 'city'])\n",
    "    info_df = pd.DataFrame(columns=['city_id','population','date','lat','long'])\n",
    "   # i=0\n",
    "    for i, url in enumerate(urls):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        lat = soup.find('span', class_='latitude').get_text()\n",
    "        longt = soup.find('span', class_='longitude').get_text()\n",
    "\n",
    "        country_row0 = soup.find(lambda tag: tag.name == 'th' and 'Country' in tag.text)\n",
    "        country = country_row0.find_next().get_text()\n",
    "\n",
    "        population_row1 = soup.find(lambda tag: tag.name == 'th' and 'Population' in tag.text)\n",
    "       # <div class=\"ib-settlement-fn\"><span class=\"nowrap\">&nbsp;</span>(2020)<sup id=\"cite_\n",
    "        date = population_row1.find_next('div').get_text()\n",
    "        population_row2 = population_row1.find_next('tr')\n",
    "        population = int(population_row2.find_next('td').get_text().replace(',', ''))\n",
    "        city = soup.find('div', class_='fn org').get_text()\n",
    "        #i=i+1\n",
    "        data_df = pd.DataFrame({'city_id':[int(i+1)],\n",
    "                                'city': [city], \n",
    "                                'population': [population],\n",
    "                                'date_retrieved':[date],\n",
    "                                'lat': [lat],\n",
    "                                'longt': [longt],\n",
    "                                'country': [country]})\n",
    "        city_population_df = pd.concat([city_population_df, data_df], ignore_index=True)\n",
    "        info_df = city_population_df[['city_id','population','date_retrieved','lat','longt']].copy()\n",
    "        city_df = city_population_df[['city_id','city']].copy()\n",
    "        city_df['city_id'] = city_df['city_id'].astype(int)\n",
    "        info_df['city_id'] = info_df['city_id'].astype(int)\n",
    "        info_df['date_retrieved'] = info_df['date_retrieved'].apply(lambda x: datetime.\n",
    "                                                strptime(re.search(r'\\((\\d{4}(?:-\\d{2}-\\d{2})?)\\)', x).group(1), \"%Y-%m-%d\") if '-' in x else datetime.\n",
    "                                                strptime(re.search(r'\\((\\d{4})\\)', x).group(1), \"%Y\"))\n",
    "        #city_df['city'][i] = city_df['city'][i].strip(\" \")\n",
    "        city_df['city'] = city_df['city'].str.strip()\n",
    "\n",
    "    return city_df, info_df\n",
    "\n",
    "def prepare_urls_for_cities(city_names):\n",
    "    urls = [\"https://en.wikipedia.org/wiki/\" + city.replace(\" \", \"_\") for city in city_names]\n",
    "    return urls\n",
    "\n",
    "def push_city_info_to_sql_table(city_df, connection_string, sql_table_name):\n",
    "    city_df.to_sql(sql_table_name,\n",
    "                   if_exists='append',\n",
    "                   con=connection_string,\n",
    "                   index=False)\n",
    "    return 'Done Successfully!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3933366c-6116-4a72-a93e-ab2a521692ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_names = [\n",
    "    \"Berlin\", \n",
    "    #\"Hamburg\", \n",
    "    #\"Munich\"\n",
    "   #\"Stuttgart\",\n",
    "    #\"Cairo\",\n",
    "    #\"Amman\",\n",
    "    #\"SÃ£o_Paulo\",\n",
    "    #\"Mexico_City\",\n",
    "    #\"Doha\",\n",
    "   # \"Tunis\",\n",
    "   # \"Algiers\",\n",
    "   # \"Cologne\",\n",
    "   # \"Frankfurt\",\n",
    "   # \"Leipzig\",\n",
    "   # \"Duesseldorf\",\n",
    "   #\"Dortmund\",\n",
    "   # \"Chicago\",\n",
    "   # \"London\",\n",
    "  #  \"Tripoli,_Libya\"\n",
    "    #\"Paris\"\n",
    "    #\"Alexandria\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bacc2f3b-bcf5-427e-b5e5-a979c04b48de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done Successfully!'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = prepare_urls_for_cities(city_names)\n",
    "city_df, info_df = get_city_info(urls)\n",
    "connection_string = create_sql_connection()\n",
    "push_city_info_to_sql_table(city_df, connection_string, 'cities')\n",
    "push_city_info_to_sql_table(info_df, connection_string, 'facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe3899-7bd8-421f-9e97-b6d8ed9fe9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
